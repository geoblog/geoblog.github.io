<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>地理博客</title>
  <subtitle>世界那么大，等你去探索</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://geoblog.github.io/"/>
  <updated>2017-07-11T00:28:35.385Z</updated>
  <id>https://geoblog.github.io/</id>
  
  <author>
    <name>曹老师</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>中国高铁“四纵四横”到“八纵八横”</title>
    <link href="https://geoblog.github.io/2017/07/10/20170710train/"/>
    <id>https://geoblog.github.io/2017/07/10/20170710train/</id>
    <published>2017-07-10T07:31:35.000Z</published>
    <updated>2017-07-11T00:28:35.385Z</updated>
    
    <content type="html"><![CDATA[<p>#视频学习<br>刚才QQ推送，介绍了中国铁路的进步，大家可以学习一下哦。（注意iframe，不然识别不了）</p>
<iframe width="500" height="500" frameborder="0" src="http://player.youku.com/embed/XMjc3NDc4OTY4MA==" allowfullscreen> </iframe>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;#视频学习&lt;br&gt;刚才QQ推送，介绍了中国铁路的进步，大家可以学习一下哦。（注意iframe，不然识别不了）&lt;/p&gt;
&lt;iframe width=&quot;500&quot; height=&quot;500&quot; frameborder=&quot;0&quot; src=&quot;http://player.youku.com/
    
    </summary>
    
    
      <category term="地理" scheme="https://geoblog.github.io/tags/%E5%9C%B0%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>20170710</title>
    <link href="https://geoblog.github.io/2017/07/10/2017%E5%B9%B4%E4%B8%8B%E5%8D%8A%E5%B9%B4%E7%9B%AE%E6%A0%87/"/>
    <id>https://geoblog.github.io/2017/07/10/2017年下半年目标/</id>
    <published>2017-07-10T07:06:02.000Z</published>
    <updated>2017-07-10T07:10:30.161Z</updated>
    
    <content type="html"><![CDATA[<h1 id="订个目标吧"><a href="#订个目标吧" class="headerlink" title="订个目标吧"></a>订个目标吧</h1><p>好久没写BLOG了，都快忘记了怎么用HEXO了。<br>今天整理了一下思路，给下半年做个计划。<br>MARKDOWN也快忘记怎么用了。。。还好有MarkdownPad…</p>
<ol>
<li>把BLOG写起来，记录一些知识碎片。</li>
<li>添加一些地理知识类的分享。</li>
<li>LIFE IS SHORT ,YOU NEED PYTHON.</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;订个目标吧&quot;&gt;&lt;a href=&quot;#订个目标吧&quot; class=&quot;headerlink&quot; title=&quot;订个目标吧&quot;&gt;&lt;/a&gt;订个目标吧&lt;/h1&gt;&lt;p&gt;好久没写BLOG了，都快忘记了怎么用HEXO了。&lt;br&gt;今天整理了一下思路，给下半年做个计划。&lt;br&gt;MARKDOW
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>2017-04-15tensorflow</title>
    <link href="https://geoblog.github.io/2017/04/15/2017-04-15tensorflow/"/>
    <id>https://geoblog.github.io/2017/04/15/2017-04-15tensorflow/</id>
    <published>2017-04-15T04:50:45.000Z</published>
    <updated>2017-04-18T08:52:24.575Z</updated>
    
    <content type="html"><![CDATA[<p>准备学习GPU版TENSORFLOW及TENSORLAYER的神经网络技术。<br>计划安装linux、WIN10双系统，开源就是力量哈哈。<br>pycharm及anaconda是必备选项。<br>做业务还是用WIN系统比较方便，LINUX做开发用吧。<br>编辑PyCharm安装目录下PyCharm 4.5.3\bin下的pycharm.exe.vmoptions 修改CACHE SIZE。</p>
<p>F——test<br>from sklearn.feature_selection import f_regression<br>return f score,p</p>
<p>pearonr<br>from scipy.stats import pearsonr<br>return r,p </p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;准备学习GPU版TENSORFLOW及TENSORLAYER的神经网络技术。&lt;br&gt;计划安装linux、WIN10双系统，开源就是力量哈哈。&lt;br&gt;pycharm及anaconda是必备选项。&lt;br&gt;做业务还是用WIN系统比较方便，LINUX做开发用吧。&lt;br&gt;编辑PyCh
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>2017-03-13notebook</title>
    <link href="https://geoblog.github.io/2017/03/13/2017-03-13notebook/"/>
    <id>https://geoblog.github.io/2017/03/13/2017-03-13notebook/</id>
    <published>2017-03-13T01:32:32.000Z</published>
    <updated>2017-03-14T08:57:39.381Z</updated>
    
    <content type="html"><![CDATA[<p>今天想一想，如果把通过一个月数据训练出来的模型去检验另一个月的数据，效果会怎么样呢？<br><img src="http://img.blog.csdn.net/20170313111846146?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbW1taXJh/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt=""><br>r_squre of etr for Feb. is  0.389003895043<br>r_squre of rfr is  0.300086648874<br>r_squre of gbr is  0.336271301841<br>r_squre of abr is  -0.00792153810961<br>r_squre of dis_knr is  0.026832730496<br>r_squre of rbf_svr is  0.439851387112<br>rbf_svr的效果最好<br>如果把这几个r2_score在0.8以上的模型的数据集合起来做一个平均，会有所提高吗？</p>
<p>print(‘r<em>squre of avg</em> is ‘,r2_score(y2,y_avr))</p>
<p>print(‘mean_squared<em>error of avg</em> is ‘,mean_squared_error(ss_y.inverse_transform(y2),ss_y.inverse_transform(y_avr)))</p>
<p>使用etr,rfr,grb,xgb,svr rbf,svr linear,<br><img src="http://i.imgur.com/byCQazM.png" alt=""><br>用PIPELINE简化代码，把多个模型的结果组合起来。<br>在线流程图<a href="https://www.processon.com/diagrams" target="_blank" rel="external">https://www.processon.com/diagrams</a><br>plam           0.006768<br>u10m           0.008958<br>o3o3_graces    0.009357<br>uwnd1000       0.009961<br>coco_graces    0.010268<br>vwnd700        0.012936<br>no2c_graces    0.013694<br>vwnd850        0.014014<br>uwnd850        0.014316<br>rh2m           0.014526<br>uwnd925        0.015299<br>mslp           0.016338<br>shum500        0.016538<br>hght1000       0.017211<br>so2c_graces    0.017572<br>v10m           0.017793<br>hght925        0.018725<br>uwnd700        0.018736<br>shum700        0.019065<br>shum1000       0.019533<br>vwnd1000       0.020989<br>t2mm           0.021139<br>uwnd500        0.022543<br>vwnd925        0.022681<br>vwnd500        0.022957<br>hght850        0.023828<br>hght500        0.026042<br>temp700        0.026952<br>temp500        0.029715<br>pm10_graces    0.031843<br>temp850        0.034730<br>temp1000       0.036947<br>pm25_graces    0.048796<br>cpre           0.049767<br>hght700        0.052401<br>temp925        0.064667<br>shum850        0.075557<br>shum925        0.096839</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;今天想一想，如果把通过一个月数据训练出来的模型去检验另一个月的数据，效果会怎么样呢？&lt;br&gt;&lt;img src=&quot;http://img.blog.csdn.net/20170313111846146?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkb
    
    </summary>
    
    
      <category term="机器学习" scheme="https://geoblog.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>2017-03-10kaggle</title>
    <link href="https://geoblog.github.io/2017/03/10/2017-03-10-kaggle/"/>
    <id>https://geoblog.github.io/2017/03/10/2017-03-10-kaggle/</id>
    <published>2017-03-10T01:42:44.000Z</published>
    <updated>2017-03-10T09:13:40.888Z</updated>
    
    <content type="html"><![CDATA[<p>今天用notebook matplotlib和seaborn对一组示例数据进行可视化分析，发现有必要对各目标变量进行LOG处理，处理前多为非正态分布，处理后可能会对预测能力有所提高。对各因素进行相关分析后发现有许多自相关的可以去掉其中一个。</p>
<pre><code>&gt;&gt;&gt; np.log([1, np.e, np.e**2, 0])
array([  0.,   1.,   2., -Inf])
</code></pre><p>对训练数据进行处理，对目标数据可以不用，因为预测时不可能对目标数据进行处理。<br>把CPRE换成[0，1]的dummy数据。</p>
<p>把两个LIST组合起来，然后排序，其中一个LIST是数值。用ZIP组合，再转成DICT，再用PD的series排序</p>
<pre><code>f_importance=pd.Series(dict(list(zip(column,etr.feature_importances_,)))).sort_values()
</code></pre><p>当训练数据为10天以内里线性方法的R_squre为0.16，当数据增加到30天时，R_squre为0.56，训练数据的增加提高了预测的R_squre。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;今天用notebook matplotlib和seaborn对一组示例数据进行可视化分析，发现有必要对各目标变量进行LOG处理，处理前多为非正态分布，处理后可能会对预测能力有所提高。对各因素进行相关分析后发现有许多自相关的可以去掉其中一个。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;
    
    </summary>
    
    
      <category term="机器学习" scheme="https://geoblog.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>2017-03-08 kaggle</title>
    <link href="https://geoblog.github.io/2017/03/08/2017-03-08kaggle/"/>
    <id>https://geoblog.github.io/2017/03/08/2017-03-08kaggle/</id>
    <published>2017-03-08T06:21:06.000Z</published>
    <updated>2017-03-10T01:40:31.494Z</updated>
    
    <content type="html"><![CDATA[<h1 id="模型评分函数"><a href="#模型评分函数" class="headerlink" title="模型评分函数"></a>模型评分函数</h1><p>sklearn.metrics.r2_score(y_true, y_pred, sample_weight=None, multioutput=None)</p>
<p>R^2 (coefficient of determination) regression score function.</p>
<p>Best possible score is 1.0 and <strong>it can be negative</strong> (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a R^2 score of 0.0.</p>
<p>Notes</p>
<p>This is not a symmetric function.<br>Unlike most other scores, R^2 score may be negative (it need not actually be the square of a quantity R).</p>
<p>用了LOG函数处理SO2后，分布变得NORM</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;模型评分函数&quot;&gt;&lt;a href=&quot;#模型评分函数&quot; class=&quot;headerlink&quot; title=&quot;模型评分函数&quot;&gt;&lt;/a&gt;模型评分函数&lt;/h1&gt;&lt;p&gt;sklearn.metrics.r2_score(y_true, y_pred, sample_weight
    
    </summary>
    
    
      <category term="机器学习" scheme="https://geoblog.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>kaggle数据清洗</title>
    <link href="https://geoblog.github.io/2017/03/07/kaggle%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/"/>
    <id>https://geoblog.github.io/2017/03/07/kaggle数据清洗/</id>
    <published>2017-03-07T03:20:19.000Z</published>
    <updated>2017-07-10T07:24:40.105Z</updated>
    
    <content type="html"><![CDATA[<p>学习机器学习回归之数据清洗。<br>把非正态分布的数据变为正态分布可用LOG函数。<br>把零与非零数据区分开来可新建一个二值变量[0，1]，选择非零的部分与预测目标进行相关分析，最后处理为dummy variables</p>
<pre><code>#convert categorical variable into dummy
df_train = pd.get_dummies(df_train)
</code></pre><p>References<br>Hair et al., 2013, Multivariate Data Analysis, 7th Edition (<a href="https://www.amazon.com/Multivariate-Data-Analysis-Joseph-Hair/dp/0138132631" target="_blank" rel="external">https://www.amazon.com/Multivariate-Data-Analysis-Joseph-Hair/dp/0138132631</a>)<br>数据处理：特征筛选，把因子中两两相关的只取其一，MISS DATA处理（删除或填补），LOG正态化，分类数据dummy处理,PCA降维(np.cumsum(pca.explained_variance<em>ratio</em>)=1时的主成分数就是目标参数)</p>
<pre><code>pca = PCA(whiten=True)
pca.fit(data)
variance = pd.DataFrame(pca.explained_variance_ratio_)
np.cumsum(pca.explained_variance_ratio_)
</code></pre><p>选择多种算法，取效果最好的那一种。再GRIDSERCHCV寻找最佳参数。<br>线性回归，SVR，集成方法，以KAGGLE社区上代码为例<a href="https://www.kaggle.com/miguelangelnieto/house-prices-advanced-regression-techniques/pca-and-regression/notebook" title="PCA and Regression" target="_blank" rel="external">https://www.kaggle.com/miguelangelnieto/house-prices-advanced-regression-techniques/pca-and-regression/notebook</a></p>
<pre><code>def lets_try(train,labels):
    results={}
       def test_model(clf):

        cv = KFold(n_splits=5,shuffle=True,random_state=45)
        r2 = make_scorer(r2_score)
        r2_val_score = cross_val_score(clf, train, labels, cv=cv,scoring=r2)
        scores=[r2_val_score.mean()]
        return scores

    clf = linear_model.LinearRegression()
    results[&quot;Linear&quot;]=test_model(clf)

    clf = linear_model.Ridge()
    results[&quot;Ridge&quot;]=test_model(clf)

    clf = linear_model.BayesianRidge()
    results[&quot;Bayesian Ridge&quot;]=test_model(clf)

    clf = linear_model.HuberRegressor()
    results[&quot;Hubber&quot;]=test_model(clf)

    clf = linear_model.Lasso(alpha=1e-4)
    results[&quot;Lasso&quot;]=test_model(clf)

    clf = BaggingRegressor()
    results[&quot;Bagging&quot;]=test_model(clf)

    clf = RandomForestRegressor()
    results[&quot;RandomForest&quot;]=test_model(clf)

    clf = AdaBoostRegressor()
    results[&quot;AdaBoost&quot;]=test_model(clf)

    clf = svm.SVR()
    results[&quot;SVM RBF&quot;]=test_model(clf)

    clf = svm.SVR(kernel=&quot;linear&quot;)
    results[&quot;SVM Linear&quot;]=test_model(clf)

    results = pd.DataFrame.from_dict(results,orient=&apos;index&apos;)
    results.columns=[&quot;R Square Score&quot;] 
    results=results.sort(columns=[&quot;R Square Score&quot;],ascending=False)
    results.plot(kind=&quot;bar&quot;,title=&quot;Model Scores&quot;)
    axes = plt.gca()
    axes.set_ylim([0.5,1])
    return results
</code></pre><p>sklearn.linear_model.HuberRegressor</p>
<p>Fit Ridge and HuberRegressor on a dataset with outliers.<br>The example shows that the predictions in ridge are strongly influenced by the outliers present in the dataset. <strong>The Huber regressor is less influenced by the outliers</strong> since the model uses the linear loss for these. As the parameter epsilon is increased for the Huber regressor, the decision function approaches that of the ridge.</p>
<p><a href="https://www.kaggle.com/jimthompson/house-prices-advanced-regression-techniques/ensemble-model-stacked-model-example/notebook" target="_blank" rel="external">https://www.kaggle.com/jimthompson/house-prices-advanced-regression-techniques/ensemble-model-stacked-model-example/notebook</a></p>
<p>To fit within the constraints of Kaggle’s Kernel offering, a simplified structure for the stacked model was used in this report. The specific simplications are</p>
<p>Limit Level 0 to three models<br>LImit Level 1 to one model<br>Improvements in stacked model performance can be accomplished by</p>
<p>Adding models to Level 0 and Level 1 using different algorithms<br>Tuning model Hyper-parameters<br>Adding feature sets by feature engineering<br>Adding levels in the model structure<br>For additional information on model stacking see these references:</p>
<p>MLWave: Kaggle Ensembling Guide<br>Kaggle Forum Posting: Stacking<br>Winning Data Science Competitions: Jeong-Yoon Lee This talk is about 90 minutes long. The sections relevant to model stacking are discussed in these segments (h:mm:ss to h:mm:ss): 1:05:25 to 1:12:15 and 1:21:30 to 1:27:00.</p>
<p>现有数据应该分为训练集和测试集，训练集拟合前应该打乱顺序时免受到时间序列的影响。交叉验证选择最优参数，然后在测试集上评分。然后</p>
<ul>
<li>选择最高分的模式作为最终模式</li>
<li>或者把多个高分模式的结果进行平均，得到一个平均数据作为最终模式结果（集成）</li>
</ul>
<p>Stacked generalization</p>
<p>Stacked generalization was introduced by Wolpert in a 1992 paper, 2 years before the seminal Breiman paper “Bagging Predictors“. Wolpert is famous for another very popular machine learning theorem: “There is no free lunch in search and optimization“.</p>
<p>The basic idea behind stacked generalization is to use a pool of base classifiers, then using another classifier to combine their predictions, with the aim of reducing the generalization error.</p>
<p>Let’s say you want to do 2-fold stacking:</p>
<p>Split the train set in 2 parts: train_a and train_b<br>Fit a first-stage model on train_a and create predictions for train_b<br>Fit the same model on train_b and create predictions for train_a<br>Finally fit the model on the entire train set and create predictions for the test set.<br>Now train a second-stage stacker model on the probabilities from the first-stage model(s).<br>A stacker model gets more information on the problem space by using the first-stage predictions as features, than if it was trained in isolation.</p>
<p>It is usually desirable that the level 0 generalizers are of all “types”, and not just simple variations of one another (e.g., we want surface-fitters, Turing-machine builders, statistical extrapolators, etc., etc.). In this way all possible ways of examining the learning set and trying to extrapolate from it are being exploited. This is part of what is meant by saying that the level 0 generalizers should “span the space”.</p>
<p>[…] stacked generalization is a means of non-linearly combining generalizers to make a new generalizer, to try to optimally integrate what each of the original generalizers has to say about the learning set. The more each generalizer has to say (which isn’t duplicated in what the other generalizer’s have to say), the better the resultant stacked generalization. Wolpert (1992) Stacked Generalization</p>
<p>Blending</p>
<p>Blending is a word introduced by the Netflix winners. It is very close to stacked generalization, but a bit simpler and less risk of an information leak. Some researchers use “stacked ensembling” and “blending” interchangeably.</p>
<p>With blending, instead of creating out-of-fold predictions for the train set, you create a small holdout set of say 10% of the train set. The stacker model then trains on this holdout set only.</p>
<p>Blending has a few benefits:</p>
<p>It is simpler than stacking.<br>It wards against an information leak: The generalizers and stackers use different data.<br>You do not need to share a seed for stratified folds with your teammates. Anyone can throw models in the ‘blender’ and the blender decides if it wants to keep that model or not.<br>The cons are:</p>
<p>You use less data overall<br>The final model may overfit to the holdout set.<br>Your CV is more solid with stacking (calculated over more folds) than using a single small holdout set.<br>As for performance, both techniques are able to give similar results, and it seems to be a matter of preference and skill which you prefer. I myself prefer stacking.</p>
<p>If you can not choose, you can always do both. Create stacked ensembles with stacked generalization and out-of-fold predictions. Then use a holdout set to further combine these models at a third stage.</p>
<p>Stacking with logistic regression</p>
<p>Stacking with logistic regression is one of the more basic and traditional ways of stacking. A script I found by Emanuele Olivetti helped me understand this.</p>
<p><strong>When creating predictions for the test set, you can do that in one go, or take an average of the out-of-fold predictors. Though taking the average is the clean and more accurate way to do this, I still prefer to do it in one go as that slightly lowers both model and coding complexity.</strong></p>
<p><a href="http://mlwave.com/kaggle-ensembling-guide/" target="_blank" rel="external">http://mlwave.com/kaggle-ensembling-guide/</a><br>上文提到了自动选择多个模型并建立集成模型，并获得了良好的效果。缺限可能在于预测所花时间较长，模型较复杂。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;学习机器学习回归之数据清洗。&lt;br&gt;把非正态分布的数据变为正态分布可用LOG函数。&lt;br&gt;把零与非零数据区分开来可新建一个二值变量[0，1]，选择非零的部分与预测目标进行相关分析，最后处理为dummy variables&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#convert ca
    
    </summary>
    
    
      <category term="机器学习" scheme="https://geoblog.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>kaggle小试2017-03-06</title>
    <link href="https://geoblog.github.io/2017/03/06/2017-03-06/"/>
    <id>https://geoblog.github.io/2017/03/06/2017-03-06/</id>
    <published>2017-03-06T04:55:14.482Z</published>
    <updated>2017-03-06T08:48:33.163Z</updated>
    
    <content type="html"><![CDATA[<h1 id="kaggle"><a href="#kaggle" class="headerlink" title="kaggle"></a>kaggle</h1><p>注册了kaggle账户，用的是yahoo.com的邮箱，用QQ邮箱注册时收到的验证链接打开后显示不了验证码。<br>看了TITANIC的示例数据及指导，下载安装WIN7 64位的</p>
<h2 id="XGBOOST"><a href="#XGBOOST" class="headerlink" title="XGBOOST"></a>XGBOOST</h2><p>参考GITHUB上的安装指引。<br>This page gives instructions on how to build and install the xgboost package from scratch on various systems. It consists of two steps:</p>
<p>First build the shared library from the C++ codes (libxgboost.so for linux/osx and libxgboost.dll for windows).<br>Exception: for R-package installation please directly refer to the R package section.<br>Then install the language packages (e.g. Python Package).<br>Important the newest version of xgboost uses submodule to maintain packages. So when you clone the repo, remember to use the recursive option as follows.</p>
<p>安装git for windows,打开git-bash</p>
<pre><code>cd c:
git clone --recursive https://github.com/dmlc/xgboost
</code></pre><p>For windows users who use github tools, you can open the git shell, and type the following command.<br>    cd xgboost<br>    git submodule init<br>    git submodule update</p>
<h2 id="Building-on-Windows"><a href="#Building-on-Windows" class="headerlink" title="Building on Windows"></a>Building on Windows</h2><p>XGBoost support both build by MSVC or MinGW. Here is how you can build xgboost library using MinGW.</p>
<p>After installing Git for Windows, you should have a shortcut Git Bash. All the following steps are in the Git Bash.</p>
<p>In MinGW, make command comes with the name mingw32-make. You can add the following line into the .bashrc file.</p>
<pre><code>alias make=&apos;mingw32-make&apos;
</code></pre><p>To build with MinGW</p>
<pre><code>cp make/mingw64.mk config.mk; make -j4
</code></pre><p>MinGW尝试，不成功。</p>
<p>To build with Visual Studio 2013 use cmake. Make sure you have a recent version of cmake added to your path and then from the xgboost directory:</p>
<pre><code>mkdir build
cd build
cmake .. -G&quot;Visual Studio 12 2013 Win64&quot;
</code></pre><p>This specifies an out of source build using the MSVC 12 64 bit generator. Open the .sln file in the build directory and build with Visual Studio. To use the Python module ,</p>
<p><strong>you can copy libxgboost.dll into<br>c:\xgboost\python-package\xgboost.</strong></p>
<pre><code>python setup.py install
</code></pre><p>安装成功。<br>ipython import xgboost ok.<br>ipython notebook 默认目录是 我的文档</p>
<p>根据教程做出的数据上传到KAGGLE评分0.78，排名2000多，呵呵<br>太过复杂的模型的泛化能力不一定就更好。</p>
<p>再看了一下BOSTON的数据及一个讨论话题，回归问题与目前工作更相关，还是挺有意思的。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;kaggle&quot;&gt;&lt;a href=&quot;#kaggle&quot; class=&quot;headerlink&quot; title=&quot;kaggle&quot;&gt;&lt;/a&gt;kaggle&lt;/h1&gt;&lt;p&gt;注册了kaggle账户，用的是yahoo.com的邮箱，用QQ邮箱注册时收到的验证链接打开后显示不了验证码。
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>现在开始记录</title>
    <link href="https://geoblog.github.io/2017/03/05/2017-03-05/"/>
    <id>https://geoblog.github.io/2017/03/05/2017-03-05/</id>
    <published>2017-03-05T02:20:30.327Z</published>
    <updated>2017-03-05T04:17:20.355Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><p>用微信连接ECT，比用APP连接更稳定。</p>
<h2 id="进口产品论证流程："><a href="#进口产品论证流程：" class="headerlink" title="进口产品论证流程："></a>进口产品论证流程：</h2><ul>
<li>下载表格，填写仪器性能需求。进行专家论证。结果返回后打印盖章。交财局审批，放在总务处靠门口的文件夹里。</li>
<li>文件上交时注意装订，或用信封装好。</li>
<li>扫描时可把多页文件一次双面扫描成PDF.</li>
</ul>
<h2 id="软件著作权申请"><a href="#软件著作权申请" class="headerlink" title="软件著作权申请"></a>软件著作权申请</h2><ul>
<li>源代吗，技术说明，用户使用说明，单位资料</li>
<li>联系公司办理。根据要求准备材料。</li>
<li>发送材料，收到发票，办理转账，35天后收材料。</li>
</ul>
<h2 id="不同作者的书的水平还是有区别的。"><a href="#不同作者的书的水平还是有区别的。" class="headerlink" title="不同作者的书的水平还是有区别的。"></a>不同作者的书的水平还是有区别的。</h2><p>这几天看了一本翻译版的书籍，文中的术语有几个让人看着比较别扭，整个过程看得人比较难受。。看完一遍感觉多是在翻译软件的使用手册，不过也算是打基础吧。<br>今天看另外一本书，作者是国人，所用术语相比上一本书要准确很多，知识介绍也比较有条理，看上去就感觉很好。<br>今天学到许多有用的知识，《python机器学习及实践》</p>
<ul>
<li>numpy 里面repeat与tile，在构建array时很有用。</li>
<li>sklearn模型数据预处理时可以先实例化对象（如ss=StandScaler()），对训练数据fit_transform后再对测试数据进行transform.</li>
</ul>
<pre><code>ss=StandScaler()
ss.fit_transform(data_train)
ss.transform(data_test)
</code></pre><ul>
<li>几个有用的术语：准确率：accuracy;精确率:precision；召回率:recall;f1得分：f1-score;</li>
<li>分类模型：线性分类，单一决策树，朴素贝叶斯，K邻近，随机森林（集合模型常用的基线系统），梯度上升，支持向量机</li>
<li>梯度法迭代渐近估计参数法，SGA用于目标最大化及SGD用于目标最小化，回归问题中是目标最小化。</li>
<li>回归模型：线性回归，支持向量机，K邻近回归，</li>
<li>用inverse_transform还原预测结果。</li>
<li>R－squared:衡量模型回归结果的波动可被真实值验证的百分比,Page 69</li>
<li>核函数配置，通过某种函数计算，将原有特征映射到更高维度的空间，从而尽可能达到新的高维度特征线性可分的程序。结合支持向量机的特点，这种高维度线性可分的数据特征恰好可以发挥其模型优势。</li>
</ul>
<h2 id="2017-02-22"><a href="#2017-02-22" class="headerlink" title="2017-02-22"></a>2017-02-22</h2><p>上午测试了把SCRAPY 安装到服务器上，运行不成功，报错type error float is not iterable.<br>以为是AQI工程的问题，换了EXAMPLE的工程还是报同样的错误。<br>可能是ANACONDA的版本问题。在WIN7 64位系统上运行是没问题的。<br>发现ANACONDA3更新到PYTHON3.6版了。下载下来装到二楼看看行不行。<br>MARKDOWN编辑的HAROOPAD在WIN系统上不太方便，下载了个MARKDOWNPAD看上去还行。<br>二楼的电脑安装PY36的ANACONDA报错 DLL LOADED FAILED，下载安装了Win32OpenSSL-1_0_2k.exe后成功。<br>在BAT文件前加上下面这几句就可以自动最小化窗口。</p>
<pre><code>@echo off
%1(start /min cmd.exe /c %0 :&amp;exit)
echo 你的代码写在这下面,最小化运行至任务栏。
pause
</code></pre><p>ANACONDA运行SCRAY失败报错，type error float object is not iterable.<br>试一试PY27版本的也不行，新建一个项目直接运行也显示上述错误。<br>there is no answer for the error online.</p>
<p>计算代码长度的工具cloc-1.64.exe<br><img src="http://img.blog.csdn.net/20170222165019160?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbW1taXJh/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="win7下使用cloc计算代码行数"></p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Quick-Start&quot;&gt;&lt;a href=&quot;#Quick-Start&quot; class=&quot;headerlink&quot; title=&quot;Quick Start&quot;&gt;&lt;/a&gt;Quick Start&lt;/h2&gt;&lt;p&gt;用微信连接ECT，比用APP连接更稳定。&lt;/p&gt;
&lt;h2 id=&quot;进
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="https://geoblog.github.io/2016/09/07/hello-world/"/>
    <id>https://geoblog.github.io/2016/09/07/hello-world/</id>
    <published>2016-09-07T09:22:24.647Z</published>
    <updated>2016-09-07T01:51:03.225Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="external">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="external">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="external">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="external">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo new <span class="string">"My New Post"</span></div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="external">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo server</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="external">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo generate</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="external">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo deploy</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="external">Deployment</a></p>
<iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="450" src="http://music.163.com/outchain/player?type=0&id=459115793&auto=0&height=430"></iframe>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>利用github and Hexo建立个人blog</title>
    <link href="https://geoblog.github.io/2016/08/27/my-new-post/"/>
    <id>https://geoblog.github.io/2016/08/27/my-new-post/</id>
    <published>2016-08-27T08:23:23.000Z</published>
    <updated>2016-09-07T02:02:27.838Z</updated>
    
    <content type="html"><![CDATA[<p>Hexo 是一个快速、简单且功能强大的 Node.js 博客框架，可以方便的生成静态网页托管在github和Heroku上。</p>
<p>GitHub Pages 可以被认为是用户编写的、托管在github上的静态网页。由于它的空间免费稳定， 可以用于介绍托管在github上的Project或者搭建网站。</p>
<p>gp 生成的网站的默认域名是 username.github.io 或者 username.github.io/project-name ，但gp是支持自定义域名的： Custom Domain Name 。购买域名之后，可以和默认的二级域名进行绑定<br><a id="more"></a></p>
<hr>
<ul>
<li>由于 Hexo 是基于 Node ，安装前要先安装 Node.js。上官网下载安装。</li>
<li>注册github，建立username.github.io的项目用于管理blog相关资料。</li>
<li><p>下载安装github for windows,用git shell安装Hexo 有些教程要先CD到根目录，这得看你的github for windows的安装位置，直接启动git shell安装就行了。进git shell测试连github                </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">ssh -T git@github.com</div><div class="line">npm install  hexo-cli -g</div></pre></td></tr></table></figure>
</li>
<li><p>cd到Hexo项目文件夹，在github文件夹下面。运行</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">hexo init Hexo</div><div class="line">npm install</div><div class="line">hexo generate</div><div class="line">hexo server</div></pre></td></tr></table></figure>
</li>
</ul>
<p>这时端口4000被打开了，我们能过浏览器打开地址， <a href="http://localhost:4000/" target="_blank" rel="external">http://localhost:4000/</a> 或者 <a href="http://0.0.0.0:4000" target="_blank" rel="external">http://0.0.0.0:4000</a> 。<br>在Hexo的 _config.yml 中修改deploy </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"># Deployment</div><div class="line">## Docs: http://hexo.io/docs/deployment.html</div><div class="line">deploy:</div><div class="line">type: git</div><div class="line">repo: https://github.com/dwqs/username.github.io.git</div><div class="line">branch: master</div><div class="line">然后还要安装 hexo-deployer-git ：</div><div class="line"></div><div class="line">npm install hexo-deployer-git -S</div><div class="line">最后利用hexo指令发布到github：</div><div class="line"></div><div class="line">hexo d</div><div class="line">//same as</div><div class="line">hexo deploy</div><div class="line"></div><div class="line">Hexo常用命令：</div><div class="line">使用git shell ，cd Hexo项目文件夹</div><div class="line">hexo new &quot;article title&quot;</div><div class="line">hexo s == hexo server</div><div class="line">hexo n == hexo new</div><div class="line">hexo clean</div><div class="line">hexo g == hexo generate</div><div class="line"></div><div class="line">hexo d == hexo deploy</div></pre></td></tr></table></figure>
<ul>
<li>使用hexo n “filename”建立新blog，用Haroopad编辑mark dwon模式的md文件，保存后刷新可看到最新的blog<iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="450" src="http://music.163.com/outchain/player?type=0&id=459115793&auto=0&height=430"></iframe></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Hexo 是一个快速、简单且功能强大的 Node.js 博客框架，可以方便的生成静态网页托管在github和Heroku上。&lt;/p&gt;
&lt;p&gt;GitHub Pages 可以被认为是用户编写的、托管在github上的静态网页。由于它的空间免费稳定， 可以用于介绍托管在github上的Project或者搭建网站。&lt;/p&gt;
&lt;p&gt;gp 生成的网站的默认域名是 username.github.io 或者 username.github.io/project-name ，但gp是支持自定义域名的： Custom Domain Name 。购买域名之后，可以和默认的二级域名进行绑定&lt;br&gt;
    
    </summary>
    
    
      <category term="hexo" scheme="https://geoblog.github.io/tags/hexo/"/>
    
  </entry>
  
</feed>
